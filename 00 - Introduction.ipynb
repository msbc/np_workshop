{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy\n",
    "NumPy is the most fundamental library to scientific computing in Python. It forms the basis for most of the important data science libraries like pandas, scipy and tensorflow.\n",
    "\n",
    "![np_ecosystem](images/np_ecosystem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is almost *everywhere* in scientific computing.\n",
    "\n",
    "For example, NumPy was an important part of the software stack used in the first imaging of a black hole (https://iopscience.iop.org/article/10.3847/0004-637X/829/1/11), and in the discovery of gravitational waves predicted by Einstein a century ago.\n",
    "\n",
    "![blackhole](images/blackhole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tao of Numpy\n",
    "\n",
    "Numpy is the foundation upon which the entire Python scientific stack is built. Its general behavior (which takes some getting used to) and its power flow from an ethos that differs from that of vanilla Python in two main ways:\n",
    "\n",
    "* **One data, many views:**  Humans tend to conceptualize mathematical objects using hiearchies of abstractions (vectors, rows vs. columns, matrices, tables, spreadsheets with tabs, etc) that help us visualize or otherwise get a handle on what mathematical objects are and what they mean in a given context.  But to computers, all numerical data is fundamentally 1D -- just a chain of bytes.  In fact, the same 1D chain of bytes can represent a bunch of different structures to us depending on how you parse it (including 2D, 3D, or  even 4D data).  Unlike plain Python, Numpy makes this distinction between the \"raw\" data and our *view* of it explicit.\n",
    "\n",
    "\n",
    "* **Vectorization:**  Suppose you have a list of 10,000 timestamps $t$, and for each value, you need to compute $\\frac{1}{2} t^2 + 5t + 4$. That's five operations per $t$ value: square $t$, multiply the result by 1/2, separately multiply $t$ by 5, add those results, and then add 4 to that.  In Python, you perform all five operations on *each* $t$ value, one at a time.  In Numpy, you perform each operation *simultaneously* on *all 10,000 $t$ values or intermediate results*.  Modern computer hardware, including GPUs, work the same way, so that difference is at the heart of Numpy's performance.\n",
    "\n",
    "This hands-on introduction to using Numpy will largely be divided along the above two lines.\n",
    "\n",
    "First, we will explore how Numpy's `ndarray` (N-dimensional array) captures this notion of \"one data, many views\".  This will require delving a little bit into Numpy's internals. This is important -- merely being exposed to this once, even if you constantly have to go look up details afterward to get your Numpy code right (we *all* do that), will save a future you weeks of frustration trying to squash vicious bugs that you just can't wrap your head around. An ounce of prevention really is worth a pound of cure here.\n",
    "\n",
    "Then, once we have `ndarray`'s behavior as a data vessel down, we'll switch our focus to additional infrastructure that Numpy provides -- namely, \"universal functions\", or `ufunc`s and *broadcasting rules* -- that enable *vectorized operations* on those arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
